{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import collections # for Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counter is a type of dictionary where elements are stored as keys and their counts are stored as values.  \n",
    "https://docs.python.org/2/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some functions we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_string_in_list(li):\n",
    "    \"\"\"This function replaces spaces with underscores in strings in provided list and returns a new list with the modified strings.\"\"\"\n",
    "    return [s.replace(' ', '_') for s in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_lists(list_container):\n",
    "    \"\"\"This function concatenates all of the list in a given container and returns the new combined list.\"\"\"\n",
    "    all_items = []\n",
    "    for item_list in list_container:\n",
    "        all_items += item_list\n",
    "    return all_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_items(li):\n",
    "    \"\"\"This function counts the number of occurences of each item in a list and returns the results in a Counter object.\"\"\"\n",
    "    item_cnt = collections.Counter()\n",
    "    for item in li:\n",
    "        item_cnt[item] += 1\n",
    "    return item_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_singles(cntr):\n",
    "    \"\"\"This function removes all items with a count of one from the provided counter object and returns the modified object.\"\"\"\n",
    "    items = list(cntr.items())\n",
    "    singles = []\n",
    "    for item, cnt in items:\n",
    "        if cnt == 1:\n",
    "            singles.append(item)\n",
    "    for item in singles:\n",
    "        del cntr[item]\n",
    "    return cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_items(cntr, n):\n",
    "    \"\"\"This function returns a list of the n most common items in the provided counter object.\"\"\"\n",
    "    return [item for item,cnt in cntr.most_common(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"featurizing\" the ingredients column taken from https://datascience.stackexchange.com/questions/11797/split-a-list-of-values-into-columns-of-a-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value2attribute(df, value_list, source_col):\n",
    "    \"\"\"This function takes a list of values and adds them to the dataframe as binary attributes.\"\"\"\n",
    "    new_df = pandas.concat([df, pandas.DataFrame(columns=value_list)], sort=False)\n",
    "    for value in value_list:\n",
    "        new_df[value] = new_df.apply(lambda x: int(value in x[source_col]), axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_data = pandas.read_json('train.json', orient='records', typ='frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace any spaces in ingredient names with underscores to make things a little easier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_data['ingredients'] = recipe_data['ingredients'].apply(fix_string_in_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of every ingredient in every recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ingredients = concatenate_lists(recipe_data['ingredients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's count the number of times each ingredient occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingrd_cnt = count_items(all_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingredients only appearing once may not be useful, so we can try removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingrd_cnt = remove_singles(ingrd_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll can take a number, num_els, of the most common ingredients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_els = 20\n",
    "most_common = most_common_items(ingrd_cnt, num_els)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we think the original ~40k rows is too much, we could randomly sample a fraction of the data.  \n",
    "random_state is a random seed to make sure that we get the same set every time we run it.  \n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html#pandas.DataFrame.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smaller_recipe_data = recipe_data.sample(frac=0.5, random_state=42)\n",
    "#smaller_recipe_data = smaller_recipe_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataframe with the most common ingredients 'featurized'. Weka has trouble loading this csv with the ingredients column, so let's drop it - we won't need it for learning anyway.  Then we'll write it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_recipe_data = value2attribute(recipe_data, most_common, 'ingredients')\n",
    "new_recipe_data = new_recipe_data.drop(columns='ingredients')\n",
    "new_recipe_data.to_csv('top20-a.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will randomly select 20 ingredients instead of choosing the 20 most common.  To do so, we'll convert the list of all ingredients to a pandas series so that we can sample it using a random seed (to make sure that we get the same set every time we run it).  We then convert the resulting series of 20 pseudorandom ingredients back to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_len = 20\n",
    "all_ingredients_df = pandas.Series(all_ingredients)\n",
    "rand_ingrd_df = all_ingredients_df.sample(n=rand_len, random_state=42)\n",
    "rand_ingrd_list = rand_ingrd_df.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll restrict our data to this random set of ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_recipe_data = value2attribute(recipe_data, rand_ingrd_list, 'ingredients')\n",
    "rand_recipe_data = rand_recipe_data.drop(columns='ingredients')\n",
    "rand_recipe_data.to_csv('rand20-a.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we can get better results from the WEKA algorithms if we join the new_recipe_data and rand_recipe_data dataframes and write the resulting dataframe to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ingrd_list = list(set(most_common) | set(rand_ingrd_list))\n",
    "new_and_rand_recipe_data = value2attribute(recipe_data, new_ingrd_list, 'ingredients')\n",
    "new_and_rand_recipe_data = new_and_rand_recipe_data.drop(columns='ingredients')\n",
    "new_and_rand_recipe_data.to_csv('top20andrand20-a.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the least commonly occurring ingredients (excluding those that only appear once.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_common = [ingrd for ingrd,cnt in ingrd_cnt.most_common()[:-num_els-1:-1]]\n",
    "least_data = value2attribute(recipe_data, least_common, 'ingredients')\n",
    "least_data = least_data.drop(columns='ingredients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the most common and least common (excluding those appearing only once) ingredients and write to CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_least_data = pandas.merge(new_recipe_data, least_data, how='inner', on=['cuisine', 'id'])\n",
    "most_least_data.to_csv('most_and_least.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we group by cuisine and take top *n* from each type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_groups = recipe_data.groupby(by='cuisine')\n",
    "# each group in the groupby object is a tuple: (group, dataframe)\n",
    "cuisine_ingrds = {}\n",
    "for group in cuisine_groups:\n",
    "    items = concatenate_lists(group[1]['ingredients'])\n",
    "    ingrds = count_items(items)\n",
    "    top5 = most_common_items(ingrds, 5)\n",
    "    cuisine_ingrds[group[0]] = top5\n",
    "# now combine them to make one list with no duplicates that we can 'featurize'\n",
    "top_from_each = set()\n",
    "for ingrds in cuisine_ingrds.values():\n",
    "    top_from_each = top_from_each.union(set(ingrds))\n",
    "top_from_each = list(top_from_each)\n",
    "from_each_data = value2attribute(recipe_data, top_from_each, 'ingredients')\n",
    "from_each_data = from_each_data.drop(columns=['id', 'ingredients'])\n",
    "from_each_data.to_csv('top_from_each.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ingredients, e.g. salt, appear in almost every type of cuisine.  Maybe it's not very useful to include ingredients that are so common.  What if we took the top *n* ingredients from each type, combined them and then subtracted the _m_ most common ingredients to all types of cuisine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
